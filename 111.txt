2   Hadoop 平台安全问题解决方法
Hadoop 是一个分布式系统, 它允许我们存储大量
的数据, 以及还可以并行处理数据. 因为支持多租户服
务, 不可避免的会存储用户相关的敏感数据, 如个人身
份信息或财务数据. 对于企业用户而言, 其 Hadoop 大
数据平台存储的海量数据往往也包含了用户相关的敏
感数据, 这些数据仅可以对有权限的真实用户可见, 因
此需要强大的认证和授权.
Hadoop 生态系统由各种组件组成, 需要保护所有
其他 Hadoop 生态系统组件. 这些 Hadoop 组件一般都
会被最终用户直接访问或被 Hadoop 核心组件内部
(HDFS 和 Map-Reduce) 访问. 2009 年, Yahoo 团队发表
论文[15]选择使用 Kerberos 做为 Hadoop 平台的身份验
证方案, 为 Hadoop 大数据平台的安全管控方案提供了
坚实的基础, 从此 Hadoop 生态系统的安全管控突飞猛
进. 我们尝试着将每个生态系统组件的安全性和每个
组件的安全解决方案做一次系统的梳理, 每个组件都
有自己的安全挑战, 需要采取特定的方案并根据需求
进行正确配置才可以确保安全.
Hadoop 大数据平台安全问题主要在两方面有体
现: 第一, 对内部 Hadoop 大数据平台需要支持多租户
安全, 确保用户的身份是可信的且具备细粒度的访问
权限控制, 保证操作不能相互影响, 数据是安全隔离的;
第二, 对外部 Hadoop 大数据平台需要支持禁止匿名用
户访问, 禁止恶意窃取用户信息, 确保用户的操作都是
被审计的, 有据可查, 保证用户数据是被加密的, 避免
泄露数据导致信息被窃取.
针对上述 Hadoop 大数据平台安全的两大方面的
问题, 解决时需要针对其全部组件, 并从身份验证、访
问授权、数据加密和操作审计[16,17]四个方向给出解决
方案.
2.1 身份验证
身份验证指验证访问系统的用户标识. Hadoop 提
供 Kerberos 作为主身份验证. 最初, SASL/GSSAPI 用
于实现 Kerberos, 并通过 RPC 连接相互验证用户, 应用
程序和 Hadoop 服务. Hadoop 还支持 HTTP Web 控制
台的“Pluggable”身份验证, 意味着 Web 应用程序
和 Web 控制台的实现者可以为 HTTP 连接实现自己
的身份验证机制, 这包括但不限于 HTTP SPNEGO 身
份验证.
Hadoop 组件支持 SASL 框架, RPC 层可以根据需
要选择 SASL Digest-MD5 认证或 SASL GSSAPI/
Kerberos 认证[18]
, 详细如下.
(1) HDFS: NameNode 和 DataNode 之间的通信通
过 RPC 连接, 并在它们之间执行相互 Kerberos 认证[19]
.
(2) YARN: 支持 Kerberos 身份验证, SASL DigestMD5 身份验证以及 RPC 连接上的委派令牌身份验证.
(3) HBase: 支持通过 RPC, HTTP 的 SASL
Kerberos 客户端安全认证.
(4) Hive: 支持 Kerberos 和 LDAP 认证, 也支持通
过 Apache Knox 的认证.
(5) Pig: 使用用户票据将作业提交到 Hadoop, 因
此, 不需要任何额外的 Kerberos 安全认证, 但在启动
Pig 之前, 用户应该使用 KDC 进行身份验证并获取有
效的 Kerberos 票据.
(6) Oozie: 可以为 Web 客户端提供 Kerberos HTTP
简单和受保护的 GSSAPI 协商机制 (SPNEGO)
身份验证, 当客户端应用程序想要向远程服务器进行
身份验证, 但不能确定要使用的身份验证协议时, 将使
用 SPNEGO 协议.
(7) Zookeeper: 在 RPC 连接上支持 SASL Kerberos
计算机系统应用 http://www.c-s-a.org.cn 2018年 第27卷 第1期
4 专论·综述 Special Issue
身份验证.
(8) Hue: 提供 SPENGO 身份验证, LDAP 身份验
证, 现在还支持 SAML SSO 身份验证.
Hadoop 认证涉及多个数据流: Kerberos RPC 认证
机制用于用户认证、应用程序和 Hadoop 服务, HTTP
SPNEGO 认证用于 Web 控制台, 以及使用委托令牌.
委托令牌是用户和 NameNode 之间用于认证用户的双
方认证协议, 它比 Kerberos 使用的三方协议更加简单
而且运行效率更高, Oozie、HDFS、MapReduce 均支
持委托令牌.
2.2 访问授权
授权是为用户或系统指定访问控制权限的过程.
Hadoop 中, 访问控制是遵循 UNIX 权限模型的、基于
文件的权限模型来实现的, 具体如下.
(1) HDFS: NameNode 基于用户、用户组的文件权
限对 HDFS 中文件进行访问控制.
(2) YARN: 为作业队列提供 ACL, 定义哪些用户
或组可以将作业提交到队列以及哪些用户或组可以更
改队列属性.
(3) HBase: 提供对表和列族的用户授权, 使用协处
理器来实现用户授权. 协处理器就像 HBase 中的数据
库触发器, 它们在前后拦截了对表的任何请求, 目前
HBase 还支撑对单元级别超细粒度访问控制.
(4) Hive: 可以依赖 HDFS 的文件权限进行控制,
也可以使用类似于 SQL 的方式实现对数据库、数据
表甚至字段级别超细粒度的访问控制.
(5) Pig: 使用 ACL 为作业队列提供授权.
(6) Oozie: 提交的任务的权限依赖 YARN 定义的
任务队列提交的权限控制.
(7) Zookeeper: 提供使用节点 ACL 的授权.
(8) Hue: 通过文件系统权限提供访问控制; 它还提
供作业队列的 ACL.
尽管 Hadoop 可以设置为通过用户和组权限和访
问控制列表 (ACL) 执行访问控制, 但这可能不足以满
足每个企业的需要, 因为各个组件均有自己的一套管
控体系导致管控入口分散, 各个组件管控的具体操作
方式也各异, 导致运维实施操作时复杂度高. 因此一般
的会采用一些集成的解决方案, 将访问授权以集中
的、可视化的方式封装起来[20]
, 降低运维操作的复杂
度, 提升效率, 这些解决方案包括: Apache Ranger、
Cloudera Sentry 等.
2.3 数据加密
加密确保用户信息的机密性和隐私性, 并且保护
Hadoop 中的敏感数据[21]
. Hadoop 是在不同的机器上
运行的分布式系统, 这意味着数据在网络上定期传输
是不可避免的, 而且对于数据挖掘的需求会要求这些
数据持续不断地写入到集群. 数据写入或读出集群时,
称之为运动的数据, 数据保存在集群内部时, 称之为静
止的数据, 全面的数据加密方案需要同时兼顾运动的
数据加密和静止的数据加密[22]
, 常见的数据加密保护
策略包括以下两条.
(1) 运动的数据加密保护策略: 在数据传输到
Hadoop 系统和从 Hadoop 系统读出数据时, 可以使用
简单认证和安全层 (SASL) 认证框架用于在 Hadoop 生
态系统中加密运动中的数据. SASL 安全性保证客户端
和服务器之间交换的数据, 并确保数据不会被“中间
人”读取. SASL 支持各种身份验证机制, 例如 DIGESTMD5, CRAM-MD5 等.
(2) 静止的数据加密保护策略: 静止的数据可以通
过两种方案加密, 方案一: 在数据存储到 HDFS 之前,
首先对整个数据文件进行加密, 然后再将加密后的文
件写入 HDFS 中. 在这种方法中, 每个 DataNode 中的
数据块不能被单独解密, 只有全部 DataNode 中全部的
数据块被读取出来后, 才可以进行解密; 方案二: 在
HDFS 层面对每一个数据块进行加密, 这个操作对于文
件写入方是无感知的, 是 HDFS 底层静默进行加密处
理的.
Hadoop 组件对于数据加密的支持如下.
(1) HDFS: 支持各种通道的加密功能, 如 RPC,
HTTP 和数据传输协议等, 可支持对运动的数据进行加
密保护; Hadoop 也支持对于静止数据的加密保护, 可
以通过 Hadoop 加密编解码器框架和加密编解码器
实现.
(2) YARN: 不存储数据, 因此不涉及数据加密.
(3) HBase: 支持使用基于 SASL 框架的 RPC 操作
提供对运动的数据进行加密; 目前暂不提供对静止数
据加密的解决方案, 但可以通过定制加密技术或第三
方工具来实现.
(4) Hive: 目前官方暂不提数据加密解决方案的数
据, 但可以通过定制加密技术或第三方工具来实现.
(5) Pig: 支持使用 SASL 对运动的数据进行加密;
目前暂不提供对静止数据加密的解决方案, 但可以通
2018年 第27卷 第1期 http://www.c-s-a.org.cn 计算机系统应用
Special Issue 专论·综述 5
过定制加密技术或第三方工具来实现.
(6) Oozie: 支持使用 SSL/TLS 对运动的数据进行
加密; 目前暂不提供对静止数据加密的解决方案, 但可
以通过定制加密技术或第三方工具来实现.
(7) Zookeeper: 目前官方暂不提数据加密解决方
案的数据, 但可以通过定制加密技术或第三方工具来
实现.
(8) Hue: 支持使用 HTTPS 对运动的数据进行加
密, 目前暂不提供对静止数据加密的解决方案, 但可以
通过定制加密技术或第三方工具来实现.
2.4 操作审计
Hadoop 集群托管敏感信息, 此信息的安全对于企
业具有成功的安全大数据使用至关重要[23]
. 即便做了
比较完善的安全管控, 但仍然存在未经授权的访问或
特权用户的不适当访问而发生安全漏洞的可能性. 因
此为了满足安全合规性要求, 我们需要定期审计整个
Hadoop 生态系统, 并部署或实施一个执行日志监视的
系统[24]
, 详细如下.
(1) HDFS: 提供对用户访问 HDFS 执行操作行为
的审计支持.
(2) YARN: 提供对用户任务提交、资源用量和资
源队列操作等行为的审计支持.
(3) HBase: 提供对用户访问 HBase 执行操作行为
的审计支持.
(4) Hive: 通过 Metastore 提供对用户访问 Hive 执
行操作行为的审计支持.
(5) Pig: 目前官方暂不提审计的功能, 但可以通过
定制加开发或第三方工具来实现.
(6) Oozie: 通过 Oozie 日志文件提供对用户执行的
分布式任务调度信息的审计支持.
(7) Zookeeper: 目前官方暂不提审计的功能, 但可
以通过定制开发或第三方工具来实现.
(8) Hue: 通过 H ue 日志文件提供对用户使用
Hue 执行操作行为的审计支持.
对于官方不提供内置审计日志记录的 Hadoop 组
件, 行业内一般通过自定义开发日志记录并结合日志
采集工具, 例如: Flume、Scribe 和 LogStash 等开源工
具, 实现审计日志数据接入到大数据平台中, 然后依托
于按需采集的日志, 搭建适合企业内部的日志管理系
统, 用以支持集中式日志记录和审核[25]
.
综上所述, Hadoop 安全问题目前在身份验证、访
问授权、数据加密和操作审计四个主要方向上均有可
用解决方案或待实现的解决思路, 对于大数据平台用
户应该合理分析自己的应用场景来明确安全保障等级,
对于平台使用到的组件不应该存在安全短板, 具体的:
在多租户场景下, 用户的身份验证和访问授权是至关
重要的; 在数据敏感场景下, 数据传输中的动态加密和
数据存储时的静态加密均需考虑; 在有问题追责体系
或用量计量需求时, 操作审计是必需具备的安全管控
能力, 但在实际生产环境中实践显示操作审计对于性
能有一定的影响, 且审计日志体量较大, 需要做好评估
和优化设计.
